#!/bin/bash

# The timestamp suffix for the top-level directory, eg. 20120904_1021
CURRENT_DATE=`date +%Y%m%d_%H%M`

indexes=indexes
ts_indexes_dir={{ts_dir}}

# The S3 backup dir
s3_backup_dir={{s3_backup_dir | default('')}}

# The starting directory
backup_dir={{ backup_dir }}

# The dir where zips go
zip_dir=$backup_dir/zips

# The working directory and the resulting archive file prefix
ARCHIVE_PREFIX="snowowl_$(hostname -s)_$CURRENT_DATE"

# The absolute path to the above
ABSOLUTE_ARCHIVE_PREFIX="$zip_dir/$ARCHIVE_PREFIX/dataset"

# The connection timeout for HTTP requests in seconds.
CONNECTION_TIMEOUT_SECONDS=5

# The username used for creating hot backups (should be a valid Snow Owl user)
SNOWOWL_USERNAME="{{ ts_user }}"

# The password for the user given above
SNOWOWL_PASSWORD="{{ ts_pw }}"

# The base URL of the REST services to use
BASE_URL="{{ base_url }}"

# The base URL for administrative services
ADMIN_BASE_URL="$BASE_URL/admin"

# The number of milliseconds to wait before giving up trying to lock the complete repository.
LOCK_TIMEOUT_MILLIS=30000

# Prints a message to stdout with the current date and time.
echo_date() {
	echo -e "[`date +\"%Y-%m-%d %H:%M:%S\"`] $@"
}

# Prints an error message to stderr and exits the script with a non-zero status.
error_exit() {
	echo -e "[`date +\"%Y-%m-%d %H:%M:%S\"`] $@" >&2
	exit 1
}

# Invokes curl to make an HTTP request to the server; stores returned message and HTTP status code in output variables.
rest_call() {
	CURL_OUTPUT=`curl -q --fail --silent --show-error --connect-timeout "$CONNECTION_TIMEOUT_SECONDS" --user "$SNOWOWL_USERNAME:$SNOWOWL_PASSWORD" --write-out "\n%{http_code}" "$@"`
	CURL_MESSAGE=`echo "$CURL_OUTPUT" | head -n-1`
	CURL_HTTP_STATUS=`echo "$CURL_OUTPUT" | tail -n1`
}

# Tries to acquire a global lock that prevents writing to any of the terminology stores on any available branch.
lock_all_repositories() {
	echo_date "Locking repositories..."
	rest_call --data-urlencode "timeoutMillis=$LOCK_TIMEOUT_MILLIS" "$ADMIN_BASE_URL/repositories/lock"
}

# Removes the lock from all repositories.
unlock_all_repositories() {
	echo_date "Unlocking repositories..."
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/repositories/unlock"
}

# Cleans up the global repository lock and exits with an error.
unlock_all_repositories_and_exit() {
	unlock_all_repositories
	error_exit "$1"
}

# Locks the specified repository, preventing write access to all of its branches.
lock_repository() {
	echo_date "Locking repository $REPOSITORY..."
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/repositories/$REPOSITORY/lock"
	
	if [ "$CURL_HTTP_STATUS" -ne "204" ]; then
		unlock_all_repositories_and_exit "Couldn't lock repository $REPOSITORY. Exiting with error."
	fi
}

# Unlocks the specified repository if it was already locked.
unlock_repository() {
	echo_date "Unlocking repository $REPOSITORY..."
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/repositories/$REPOSITORY/unlock"
}

# Unlocks the specified repository, cleans up the global repository lock and exits with an error.
unlock_repository_and_exit() {
	unlock_repository
	unlock_all_repositories_and_exit "$1"
}

# Main script starts here.
main() {
	echo_date "----------------------------"
	#check_arguments
	
	lock_all_repositories

	echo_date "Create backup destination directory '$ABSOLUTE_ARCHIVE_PREFIX'."
	mkdir -pv "$ABSOLUTE_ARCHIVE_PREFIX" || error_exit "Couldn't create directory '$ABSOLUTE_ARCHIVE_PREFIX'. Exiting with error."
	echo_date "Starting backup; sending message to connected users."
	#echo_date "Rsync'ing indexes..."
	rsyncindexes
	echo_date "dumping mysql..."
    mysql_dump &
    unlock_all_repositories
    wait
    
    echo_date "copying from rsync folder..."
    copyfromrsyncdir
	echo_date "Creating archive..."
	echo_date "ARCHIVE_PREFIX.zip = $ARCHIVE_PREFIX.zip"
	echo_date "ARCHIVE_PREFIX = $ARCHIVE_PREFIX"
	cd "$zip_dir"
	zip --recurse-paths --move --test "$ARCHIVE_PREFIX.zip" "$ARCHIVE_PREFIX" || error_exit "Archive creation failed; the backup is incomplete. Exiting with error."
	
	echo_date "Finished successfully."
	delete_old
	movetoaws
	exit 0
}

mysql_dump(){
echo_date "dumping mysql...to $ABSOLUTE_ARCHIVE_PREFIX/{{ dump_filename }}"
/usr/bin/mysqldump -uroot -p{{ mysql_root_pass }} --databases {{ ts_dbname }} {{ ts_review_dbname }} --quick --single-transaction > $ABSOLUTE_ARCHIVE_PREFIX/{{ dump_filename }}
}

rsyncindexes(){
mkdir -pv {{ rsync_dir }}
 /usr/bin/rsync  -av --delete --no-compress $ts_indexes_dir {{ rsync_dir }}
}

copyfromrsyncdir(){
cp -R {{ rsync_dir }}/$indexes $ABSOLUTE_ARCHIVE_PREFIX
}

movetoaws(){
	echo "s3_backup_dir = "$s3_backup_dir;
	# sync to amazon if s3 dest is defined & the ~/.aws/config file exists
	if [ -f ~/.aws/config ] && [ "$s3_backup_dir" != "" ];
	then
		echo "Transferring backup to AWS S3";
		/usr/bin/aws s3 sync ${zip_dir} $s3_backup_dir --delete;
		echo "Backup transferred";
		echo "Backup process complete";
	else
		echo "Skipping backup to S3 due to lack of configuration.  Check ~/.aws/config file exists and s3_backup_dir defined."
	fi
}

delete_old() { 
echo "Cleaning up old backups prior to moving them to aws"
 if [ -d $zip_dir ] && [ "$zip_dir" != "" ] ;
  then   
   echo "Deleting old back ups backup dir = "${zip_dir}; 
   find ${zip_dir}/* -mtime +5 -exec rm {} \;
 fi
}

# Ensures that only a single instance is running at any time
LOCKFILE="{{script_dir}}/instance.lock"

(
        flock -n 200 || error_exit "Another backup script is already running. Exiting with error."
        trap "rm $LOCKFILE" EXIT
        main
) 200> $LOCKFILE

