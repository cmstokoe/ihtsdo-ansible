#!/usr/bin/env bash

###############################################################################
# Copyright (c) 2014 B2i Healthcare. All rights reserved.
###############################################################################

# This sample backup script for the Snow Owl Server creates a .zip file in the 
# current directory with the saved contents of the MySQL databases and semantic
# indexes for each terminology, as well as supporting index content.
#
# The server should be stopped before running the script.
#
# The following variables should be set by editing this script before running it:
# The S3 backup dir
s3_backup_dir="{{s3_backup_dir | default('')}}"
# The location of the Snow Owl Server installation, eg. /opt/snowowl (no trailing slash)
SNOW_OWL_SERVER_HOME="{{ term_serv_dir }}"

# The MySQL username used for creating the database dump
MYSQL_USERNAME="{{ ts_user }}"

# The password for the user given above
MYSQL_PASSWORD="{{ ts_pw }}"

# The timestamp suffix for the top-level directory, eg. 20120904_1021
CURRENT_DATE=`date +%Y%m%d_%H%M`

# The starting directory
backup_dir="{{ backup_dir }}"

# The dir where zips go
zip_dir="{{ backup_zip_dir }}"

# The working directory and the resulting archive file prefix
ARCHIVE_PREFIX="snowowl_$(hostname -s)_$CURRENT_DATE"

# The absolute path to the above
ABSOLUTE_ARCHIVE_PREFIX="$zip_dir/$ARCHIVE_PREFIX"

# The list of known terminology stores to preserve
REPOSITORIES=( atcStore icd10Store icd10amStore \
localterminologyStore loincStore snomedStore \
valuesetStore \
sddStore mappingsetStore )

# The list of index directories to preserve
INDEXES=( atc icd10 icd10am \
localterminology loinc snomed \
valuesets \
sdd mappingset \
bookmarks previous_picks tasks )

# Prints a message to stdout with the current date and time.
echo_date() {
	echo -e "[`date +\"%Y-%m-%d %H:%M:%S\"`] $@"
}

# Prints an error message to stderr and exits the script with a non-zero status.
error_exit() {
	echo -e "[`date +\"%Y-%m-%d %H:%M:%S\"`] $@" >&2
	exit 1
}

# Checks input arguments and test whether the script is ready to be executed.
check_arguments() {
	if [ "x$SNOW_OWL_SERVER_HOME" = "x" ]; then
		error_exit "Please set the variable SNOW_OWL_SERVER_HOME before running this script. Exiting with error."
	fi

	if [ "x$MYSQL_USERNAME" = "x" ]; then
		error_exit "Please set the variable MYSQL_USERNAME before running this script. Exiting with error."
	fi
	
	if [ "x$MYSQL_PASSWORD" = "x" ]; then
		error_exit "Please set the variable MYSQL_PASSWORD before running this script. Exiting with error."
	fi
	
	if [ ! -d "$SNOW_OWL_SERVER_HOME/resources/indexes" ]; then
		error_exit "No index directory could be found for the installation under '$SNOW_OWL_SERVER_HOME'. Exiting with error."
	fi
}

# Saves content from a single index.
backup_index() {
	echo_date "Saving contents of index '$INDEX'..."
	
	# Need to switch directories because of relative paths within the zip
	cd "$SNOW_OWL_SERVER_HOME/resources/indexes" || error_exit "Couldn't switch to index directory '$SNOW_OWL_SERVER_HOME/resources/indexes'. Exiting with error." 
	rsync --verbose --recursive --dirs --exclude=segments.gen --exclude=write.lock "$INDEX" "$ABSOLUTE_ARCHIVE_PREFIX" || error_exit "Couldn't copy files for index '$INDEX'. Exiting with error."
}

# Saves all index content to the destination archive.
backup_indexes() {
	echo_date "Saving index content..."

	for INDEX in "${INDEXES[@]}"; do
		backup_index || break
	done
	
	# Check if the loop above was left via a break
	if [ $? -ne 0 ]; then exit 1; fi
	
	echo_date "Done saving index content."
}

# Saves content from a single repository.
backup_repository() {
	cd "$zip_dir"
	DATABASE_DUMP_FILE="$REPOSITORY.sql"
	
	echo_date "Creating SQL dump from contents of repository $REPOSITORY to $DATABASE_DUMP_FILE..."
	mysqldump --user="$MYSQL_USERNAME" --password="$MYSQL_PASSWORD" "$REPOSITORY" > "$ABSOLUTE_ARCHIVE_PREFIX/$DATABASE_DUMP_FILE" || error_exit "Couldn't create SQL dump for repository $REPOSITORY. Exiting with error."
}

# Saves all terminology content in database dumps and moves them to the destination archive.
backup_repositories() {
	echo_date "Backing up installed terminology repositories..."
	
	for REPOSITORY in "${REPOSITORIES[@]}"; do
		backup_repository || break
	done
	
	# Check if the loop above was left via a break
	if [ $? -ne 0 ]; then exit 1; fi
	
	echo_date "Done backing up installed repositories."
}

# Main script starts here.
main() {
	echo_date "----------------------------"
	check_arguments
	
	echo_date "Creating backup destination directory '$ABSOLUTE_ARCHIVE_PREFIX'."
	mkdir -pv "$ABSOLUTE_ARCHIVE_PREFIX" || error_exit "Couldn't create directory '$ABSOLUTE_ARCHIVE_PREFIX'. Exiting with error."

	backup_repositories
	backup_indexes
	
	echo_date "Creating archive..."
	cd "$zip_dir"
	zip --recurse-paths --move --test "$ARCHIVE_PREFIX.zip" "$ARCHIVE_PREFIX" || error_exit "Archive creation failed; the backup is incomplete. Exiting with error."
	
	echo_date "Finished backup successfully."
	delete_old
	movetoaws
	exit 0
}

movetoaws(){
	echo "s3_backup_dir = "$s3_backup_dir;
	# sync to amazon if s3 dest is defined & the ~/.aws/config file exists
	if [ -f ~/.aws/config ] && [ "$s3_backup_dir" != "" ];
	then
		echo "Transferring backup to AWS S3";
		/usr/bin/aws s3 sync ${zip_dir} $s3_backup_dir --delete;
		echo "Backup transferred";
		echo "Backup process complete";
	else
		echo "Skipping backup to S3 due to lack of configuration.  Check ~/.aws/config file exists and s3_backup_dir defined."
	fi
}

delete_old() { 
echo "Cleaning up old backups prior to moving them to aws"
 if [ -d $zip_dir ] && [ "$zip_dir" != "" ] ;
  then   
   echo "Deleting old back ups backup dir = "${zip_dir}; 
   find ${zip_dir}/* -mtime +5 -exec rm {} \;
 fi
}

# Ensures that only a single instance is running at any time
LOCKFILE="$backup_dir/instance.lock"

(
        flock -n 200 || error_exit "Another backup script is already running. Exiting with error."
        trap "rm $LOCKFILE" EXIT
        main
) 200> $LOCKFILE
