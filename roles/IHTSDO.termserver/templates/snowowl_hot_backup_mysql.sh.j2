#!/usr/bin/env bash

###############################################################################
# Copyright (c) 2014 B2i Healthcare. All rights reserved.
###############################################################################

# This sample backup script for the Snow Owl Server creates a .zip file in the 
# current directory with the saved contents of the MySQL databases and semantic
# indexes for each terminology, as well as supporting index content, while the
# server is kept running.

# The following variables should be set by editing this script before running it:
# The S3 backup dir
s3_backup_dir="{{s3_backup_dir | default('')}}"
# The location of the Snow Owl Server installation, eg. /opt/snowowl (no trailing slash)
SNOW_OWL_SERVER_HOME="{{ term_serv_dir }}"

# The username used for creating hot backups (should be a valid Snow Owl user)
SNOWOWL_USERNAME="{{ snow_user }}"

# The password for the user given above
SNOWOWL_PASSWORD="{{ snow_pw }}"

# The MySQL username used for creating the database dump
MYSQL_USERNAME="{{ ts_user }}"

# The password for the user given above
MYSQL_PASSWORD="{{ ts_pw }}"

# The timestamp suffix for the top-level directory, eg. 20120904_1021
CURRENT_DATE=`date +%Y%m%d_%H%M`

# The number of milliseconds to wait before giving up trying to lock the complete repository.
LOCK_TIMEOUT_MILLIS=30000

# The connection timeout for HTTP requests in seconds.
CONNECTION_TIMEOUT_SECONDS=5

# The initial waiting time after sending a message to connected users in minutes.
INITIAL_WAIT_MINUTES=5

# The number of retries the first lock is attempted.
RETRIES=5

# The waiting time after an unsuccessful lock attempt in minutes.
RETRY_WAIT_MINUTES=5

# The starting directory
backup_dir="{{ backup_dir }}"

# The dir where zips go
zip_dir="{{ backup_zip_dir }}"

# The working directory and the resulting archive file prefix
ARCHIVE_PREFIX="snowowl_$(hostname -s)_$CURRENT_DATE"

# The absolute path to the above
ABSOLUTE_ARCHIVE_PREFIX="$zip_dir/$ARCHIVE_PREFIX"

# The indexes folder within the ABSOLUTE_ARCHIVE_PREFIX
ABSOLUTE_ARCHIVE_INDEXES="$ABSOLUTE_ARCHIVE_PREFIX/{{ term_serv_indexes_dir }}"

# The base URL of the REST services to use
BASE_URL="{{ base_url }}"

# The base URL for administrative services
ADMIN_BASE_URL="$BASE_URL/admin"

# Prints a message to stdout with the current date and time.
echo_date() {
	echo -e "[`date +\"%Y-%m-%d %H:%M:%S\"`] $@"
}

# Prints an error message to stderr and exits the script with a non-zero status.
error_exit() {
	echo -e "[`date +\"%Y-%m-%d %H:%M:%S\"`] $@" >&2
	exit 1
}

# Invokes curl to make an HTTP request to the server; stores returned message and HTTP status code in output variables.
rest_call() {
	CURL_OUTPUT=`curl -q --fail --silent --show-error --connect-timeout "$CONNECTION_TIMEOUT_SECONDS" --user "$SNOWOWL_USERNAME:$SNOWOWL_PASSWORD" --write-out "\n%{http_code}" "$@"`
	CURL_MESSAGE=`echo "$CURL_OUTPUT" | head -n-1`
	CURL_HTTP_STATUS=`echo "$CURL_OUTPUT" | tail -n1`
}

# Tries to acquire a global lock that prevents writing to any of the terminology stores on any available branch.
lock_all_repositories() {
	echo_date "Locking repositories..."
	rest_call --data-urlencode "timeoutMillis=$LOCK_TIMEOUT_MILLIS" "$ADMIN_BASE_URL/repositories/lock"
}

# Removes the lock from all repositories.
unlock_all_repositories() {
	echo_date "Unlocking repositories..."
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/repositories/unlock"
}

# Cleans up the global repository lock and exits with an error.
unlock_all_repositories_and_exit() {
	unlock_all_repositories
	error_exit "$1"
}

# Locks the specified repository, preventing write access to all of its branches.
lock_repository() {
	echo_date "Locking repository $REPOSITORY..."
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/repositories/$REPOSITORY/lock"
	
	if [ "$CURL_HTTP_STATUS" -ne "204" ]; then
		unlock_all_repositories_and_exit "Couldn't lock repository $REPOSITORY. Exiting with error."
	fi
}

# Unlocks the specified repository if it was already locked.
unlock_repository() {
	echo_date "Unlocking repository $REPOSITORY..."
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/repositories/$REPOSITORY/unlock"
}

# Unlocks the specified repository, cleans up the global repository lock and exits with an error.
unlock_repository_and_exit() {
	unlock_repository
	unlock_all_repositories_and_exit "$1"
}

# Save index content for the specified version of the repository
backup_repository_index_version() {
	echo_date "Saving index content for version $VERSION of repository $REPOSITORY..."
	
	# Need to switch directories because of relative paths within the target directory
	cd "$SNOW_OWL_SERVER_HOME/resources/indexes" || unlock_repository_and_exit "Couldn't switch to index directory in $SNOW_OWL_SERVER_HOME/resources/indexes. Exiting with error." 
	rest_call "$ADMIN_BASE_URL/repositories/$REPOSITORY/versions/$VERSION/indexFiles"
	
	if [ "$CURL_HTTP_STATUS" -ne "200" ]; then
		unlock_repository_and_exit "Couldn't retrieve list of files to save for version $VERSION of repository $REPOSITORY. Exiting with error."
	fi
	
	# The returned REST message will contain the list of files (one per each line), which we pass to xargs.
	if [ ! -z "$CURL_MESSAGE" ]; then
		echo "$CURL_MESSAGE" | xargs --delimiter='\n' --max-lines=1 cp --verbose --parents --target-directory="$ABSOLUTE_ARCHIVE_INDEXES" || unlock_repository_and_exit "Couldn't copy files for version $VERSION of repository $REPOSITORY. Exiting with error."
	fi

	# Return to the initial directory.
	cd "$zip_dir"
}

# Save index content for all versions
backup_repository_index_versions() {
	echo_date "Saving index content for repository $REPOSITORY..."
	rest_call "$ADMIN_BASE_URL/repositories/$REPOSITORY/versions"
	
	if [ "$CURL_HTTP_STATUS" -ne "200" ]; then
		unlock_repository_and_exit "Couldn't retrieve list of versions for repository $REPOSITORY. Exiting with error."
	fi
	
	echo "$CURL_MESSAGE" | while read -r VERSION
	do
		backup_repository_index_version || break
	done
	
	# Check if the loop above was left via a break 
	if [ $? -ne 0 ]; then exit 1; fi
}

# Copies the contents of the specified repository to the zip file.
backup_repository() {
	lock_repository
	
	cd "$zip_dir"
	DATABASE_DUMP_FILE="$REPOSITORY.sql"
	
	echo_date "Creating SQL dump from contents of repository $REPOSITORY..."
	mysqldump --user="$MYSQL_USERNAME" --password="$MYSQL_PASSWORD" "$REPOSITORY" > "$ABSOLUTE_ARCHIVE_PREFIX/$DATABASE_DUMP_FILE" || unlock_repository_and_exit "Couldn't create SQL dump for repository $REPOSITORY. Exiting with error."

	backup_repository_index_versions
	unlock_repository
	
	echo_date "Done backing up repository $REPOSITORY."
}

# Retrieves the list of terminology repositories and backs them up one by one.
backup_repositories() {
	echo_date "Backing up installed terminology repositories..."
	rest_call "$ADMIN_BASE_URL/repositories"
	
	if [ "$CURL_HTTP_STATUS" -ne "200" ]; then
		unlock_all_repositories_and_exit "Failed to retrieve list of repositories. Exiting with error."
	fi
	
	echo "$CURL_MESSAGE" | while read -r REPOSITORY
	do
		backup_repository || break
	done
	
	# Check if the loop above was left via a break
	if [ $? -ne 0 ]; then exit 1; fi
	
	echo_date "Done backing up installed repositories."
}

# Creates a snapshot for the current supporting index, storing it in an output variable.
create_snapshot() {
	rest_call --data-urlencode "" "$ADMIN_BASE_URL/supportingIndexes/$INDEX/snapshots"
	
	if [ "$CURL_HTTP_STATUS" -ne "201" ]; then
		unlock_all_repositories_and_exit "Couldn't create snapshot for supporting index $INDEX. Exiting with error."
	fi

	SNAPSHOT="$CURL_MESSAGE"
}

# Releases the snapshot for the current supporting index.
release_snapshot() {
	rest_call -X DELETE "$ADMIN_BASE_URL/supportingIndexes/$INDEX/snapshots/$SNAPSHOT"
	
	if [ "$CURL_HTTP_STATUS" -ne "204" ]; then
		unlock_all_repositories_and_exit "Couldn't release snapshot $SNAPSHOT of supporting index $INDEX. Exiting with error."
	fi
}

# Releases the snapshot for the current supporting index and the global repository lock, then exits with an error.
relase_snapshot_and_exit() {
	release_snapshot
	unlock_all_repositories_and_exit "$1"
}

# Copies the contents of the specified supporting index snapshot to the zip file.
backup_supporting_index_snapshot() {
	echo_date "Saving index content for snapshot $SNAPSHOT of supporting index $INDEX..."
	
	# Need to switch directories because of relative paths within the zip
	cd "$SNOW_OWL_SERVER_HOME/resources/indexes" || unlock_repository_and_exit "Couldn't switch to index directory in $SNOW_OWL_SERVER_HOME/resources/indexes. Exiting with error."
	rest_call "$ADMIN_BASE_URL/supportingIndexes/$INDEX/snapshots/$SNAPSHOT"
	
	if [ "$CURL_HTTP_STATUS" -ne "200" ]; then
		release_snapshot_and_exit "Couldn't retrieve list of files to save for snapshot $SNAPSHOT of supporting index $INDEX. Exiting with error."
	fi
	
	if [ ! -z "$CURL_MESSAGE" ]; then
		echo "$CURL_MESSAGE" | xargs --delimiter='\n' --max-lines=1 cp --verbose --parents --target-directory="$ABSOLUTE_ARCHIVE_INDEXES" || unlock_repository_and_exit "Couldn't copy files for snapshot $SNAPSHOT of supporting index $INDEX. Exiting with error."
	fi
	
	# Return to the initial directory.
	cd "$zip_dir"
}

# Creates a snapshot of the specified supporting index, then saves its content.
backup_supporting_index() {
	create_snapshot
	backup_supporting_index_snapshot
	release_snapshot
	
	echo_date "Done backing up supporting index $INDEX."
}

# Retrieves the list of supporting indexes and backs them up one by one.
backup_supporting_indexes() {
	echo_date "Backing up supporting indexes..."
	rest_call "$ADMIN_BASE_URL/supportingIndexes"
	
	if [ "$CURL_HTTP_STATUS" -ne "200" ]; then
		unlock_all_repositories_and_exit "Failed to retrieve list of supporting indexes. Exiting with error."
	fi
	
	echo "$CURL_MESSAGE" | while read -r INDEX
	do
		backup_supporting_index || break
	done
	
	# Check if the loop above was left via a break
	if [ $? -ne 0 ]; then exit 1; fi
	
	echo_date "Done backing up supporting indexes."
}
backup_dir
# Sends a message to connected users.
send_message() {
	rest_call -H "Content-Type:text/plain" --data "$1" "$ADMIN_BASE_URL/messages/send"
}

# Checks input arguments and test whether the script is ready to be executed.
check_arguments() {
	if [ "x$SNOW_OWL_SERVER_HOME" = "x" ]; then
		error_exit "Please set the variable SNOW_OWL_SERVER_HOME before running this script. Exiting with error."
	fi

	if [ ! -d "$SNOW_OWL_SERVER_HOME/resources/indexes" ]; then
		error_exit "No index directory could be found for the installation under '$SNOW_OWL_SERVER_HOME'. Exiting with error."
	fi
	
	if [ "x$SNOWOWL_USERNAME" = "x" ]; then
		error_exit "Please set the variable SNOWOWL_USERNAME before running this script. Exiting with error."
	fi
	
	if [ "x$SNOWOWL_PASSWORD" = "x" ]; then
		error_exit "Please set the variable SNOWOWL_PASSWORD before running this script. Exiting with error."
	fi

	if [ "x$MYSQL_USERNAME" = "x" ]; then
		error_exit "Please set the variable MYSQL_USERNAME before running this script. Exiting with error."
	fi
	
	if [ "x$MYSQL_PASSWORD" = "x" ]; then
		error_exit "Please set the variable MYSQL_PASSWORD before running this script. Exiting with error."
	fi
}

# Main script starts here.
main() {
	echo_date "----------------------------"
	check_arguments

	echo_date "Create backup destination directory '$ABSOLUTE_ARCHIVE_PREFIX'."
	mkdir -pv "$ABSOLUTE_ARCHIVE_PREFIX" || error_exit "Couldn't create directory '$ABSOLUTE_ARCHIVE_PREFIX'. Exiting with error."
	mkdir -pv "$ABSOLUTE_ARCHIVE_INDEXES" || error_exit "Couldn't create directory '$ABSOLUTE_ARCHIVE_INDEXES'. Exiting with error."
	echo_date "Starting backup; sending message to connected users."
	send_message "Write access to repositories will be disabled while the system creates a backup in $INITIAL_WAIT_MINUTES minutes."
	
	if [ "$CURL_HTTP_STATUS" = "000" ]; then
		error_exit "Couldn't send message to users; the server is not running. Exiting with error."
	fi
	
	echo_date "Waiting $INITIAL_WAIT_MINUTES minutes for users to finish..."
	sleep "$INITIAL_WAIT_MINUTES"m
	
	for i in $(seq 1 "$RETRIES"); do 
		lock_all_repositories

		if [ "$CURL_HTTP_STATUS" -ne "204" ]; then
			echo_date "Couldn't lock repositories, waiting $RETRY_WAIT_MINUTES minutes to retry ($i)..."
			sleep "$RETRY_WAIT_MINUTES"m
		else
			break
		fi
	done
	
	if [ "$CURL_HTTP_STATUS" -ne "204" ]; then
		error_exit "Couldn't lock repositories after $RETRIES attempts. Exiting with error."
	fi
	
	backup_repositories
	backup_supporting_indexes
	unlock_all_repositories
	
	echo_date "Notifying users that write access has been restored."
	send_message "Write access to repositories restored."	

	echo_date "Creating archive..."
	cd "$zip_dir"
	zip --recurse-paths --move --test "$ARCHIVE_PREFIX.zip" "$ARCHIVE_PREFIX" || error_exit "Archive creation failed; the backup is incomplete. Exiting with error."
	
	echo_date "Finished successfully."
	delete_old
	movetoaws
	exit 0
}

movetoaws(){
echo "s3_backup_dir = "$s3_backup_dir;
# sync to amazon if s3 dest is defined & the ~/.aws/config file exists
if [ -f ~/.aws/config ] && [ "$s3_backup_dir" != "" ];
then
echo "Transferring backup to AWS S3";
/usr/bin/aws s3 sync ${zip_dir} $s3_backup_dir --delete;
echo "Backup transferred";
echo "Backup process complete";
fi
}

delete_old() { 
echo "Cleaning up old backups prior to moving them to aws"
 if [ -d $zip_dir ] && [ "$zip_dir" != "" ] ;
  then   
   echo "Deleting old back ups backup dir = "${zip_dir}; 
   find ${zip_dir}/* -mtime +5 -exec rm {} \;
 fi
}

# Ensures that only a single instance is running at any time
LOCKFILE="$backup_dir/instance.lock"

(
        flock -n 200 || error_exit "Another backup script is already running. Exiting with error."
        trap "rm $LOCKFILE" EXIT
        main
) 200> $LOCKFILE
